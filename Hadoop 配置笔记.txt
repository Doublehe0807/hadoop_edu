本文主要关注在ubuntu 环境安装hadoop 环境。本实验是在ubuntu的虚拟机环境上进行。
1. 环境准备 
   1.1 ubuntu 系统
   win7 直接使用ubantu 原生虚拟镜像，用visual box或者VMware 打开。
   win10 使用Hyper-V 虚拟服务，直接创建ubuntu 系统

   1.2 JDK， 因为hadoop 生态体系是运行在java的环境上的，所以JDK 必不可少，本文安装的是1.7 版本的JDK

		JDK 在oracle opensource 已经找不到了，通过以下网站下载binary版本

	      http://jdk.java.net/java-se-ri/7

	    准备JDK 7 环境安装方法参考以下链接
		https://www.cnblogs.com/c-xiaohai/p/6511294.html
	
		当java 安装好以后，添加java的环境变量，添加环境变量到 /etc/profile 文件
	
		export JAVA_HOME=/usr/local/java-se-7u75-ri/

		export JRE_HOME=/usr/local/java-se-7u75-ri/jre 	

		export PATH=$PATH:/usr/local/java-se-7u75-ri/bin 

		export CLASSPATH=./:/usr/local/java-se-7u75-ri/lib:/usr/local/java-se-7u75-ri/jre/lib
		
		添加到文件以后，通过运行 sudo source /etc/profile 来使更新立即生效
		
2. 开始安装haoop 环境	
    2.1 下载hadoop 包，以下链接有这个包的详细信息，本文安装了hadoop 2.2.7 版本,下载完成的包移动到安装目录，本文的安装目录是/usr/local, 解压完成可以删除相应的gz文件。
	https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.7.7/
	2.2 linux 环境准备
		2.2.1 添加一个host
			vim /etc/hosts
			添加  127.0.0.1   YARN001
	2.3  hadoop 安装
		2.3.1 解压下载好的hadoop 安装包
		sudo tar -zxvf hadoop-2.7.7.tar.gz
		cd hadoop-2.7.7/  (解压后的路径）
		2.3.2 修改配置文件
		1 ./etc/hadoop/hadoop-env.sh -->修改JAVA_HOME 到实际的$JAVA_HOME,使用绝对路径
		2 ./etc/hadoop/mapred-site.xml  --> 添加以下内容到文件(文件内容解释： 这段内容指定mapreduce使用yarn 作为hdfs 的管理环境)
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
		
		3 ./etc/hadoop/core-site.xml  -->添加如下内容到文件(内容解释：这段内容指定hdfs 的内容服务端口为本地的9001 端口)
	        <property>
                <name>fs.default.name</name>
                <value>hdfs://YARN001:9001</value>
        </property>
   
		4. ./etc/hadoop/hdfs-site.xml -->添加replication 信息 以及node dir. (内容解释： 第一段内容指定我们的节点是有多少个，因为我们目前搭建的是伪分布式系统，目前只有一个节点。 
																		第二段内容和第三段指定我们的nodeDir 和dataDir 的路径， 目前的内容是我个人服务器的路径，请根据自身的环境进行更改)
        <property>
                <name>dfs.replication</name>
                <value>1</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>/home/cindy/hadoop/dfs/name</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>/home/cindy/hadoop/dfs/data</value>
        </property>

   
		5. sudo vim ./etc/hadoop/yarn-site.xml  -->添加以下信息到yarn 环境，指定yarn的node 环境为mapreduce_shuffle.
   
		<property>
			<name>yarn.nodemanager.aux.services</name>
			<value>mapreduce_shuffle</value>
		</property>

		
3   配置完毕，启动hadoop 服务
    3.1 启动hdfs
	3.1.1 启动name node：  
	1. bin/hadoop namenode -format(初始化name code， 此操作只能在第一次启动name node的时候操作， 如果在一个已经安装好的环境操作会造成灾难性的后果) 
	2. 启动sbin/hadoop-daemon.sh start namenode
	
	3.1.2. 启动data node  
	sbin/hadoop-daemon.sh start datanode
	
	
	启动以后， 可以通过查看进程观察 namenode和datanode的情况，如果没有启动成功到 ./log/**.log 文件查看安装的日志，如果有错误，可以吧错误贴到百度，会有很多人遇到过类似的错误以及解决办法。
	
	cindy@cindy-Virtual-Machine:/usr/local/hadoop-2.7.7$ $JAVA_HOME/bin/jps
	36146 Jps
	36075 NameNode
	35772 DataNode
	
	启动成功可以通过web 端访问： http://yarn001:50070 访问hdfs， 并监控hdfs 的运行情况。
	
	
	3.1.3 可以用以下命令尝试创建HDFS 的文件系统 
	bin/hadoop fs -mkdir /home/
	bin/hadoop fs -mkdir /home/cindy/
	bin/hadoop fs -put README.txt /home/cindy/
	
	3.2. 启动yarn （可以一次性启动）
		3.1.1:运行以下命令，直接启动yarn 服务
			sbin/start-yarn.sh 
	
	在启动yarn的时候需要ssh 服务， 可能会遇到ssh 22 端口没有打开的issue,以下链接有详细的如何打开ssh 22 端口的方法。
	https://blog.csdn.net/qq_22616665/article/details/73500730
	
	启动起来以后可以通过web http://yarn001:8088 访问也可以通过$JAVA_HOME/bin/jps 查看相关进程
	
	
	3.3 跑mapreduce 样例程序，来验证是否hdfs 和yarn 正常启动了 
	
	    bin/hadoop jar /usr/local/hadoop-2.7.7/share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-2.7.7-test-sources.jar pi 2 100 查看程序的启动情况。
	
    4. 关闭yarn 和dfs
	   1. run sbin/stop-yarn.sh
	   2. run sbin/stop-dfs.sh
	   
	   第二次需要再启动hadoop的时候可以直接运行
	   1.sbin/start-dfs.sh
	   2.sbin/start-yarn.sh 来启动hadoop的环境
		  
		  
Spark 安装详细步骤：
https://www.cnblogs.com/tijun/p/7561718.html	


Spark 学习教程

https://www.bilibili.com/video/av13765160/  --陈超	  
	
	
	
	
   

   
	
	
	